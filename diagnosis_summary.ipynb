{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recording the conversation. Press Enter to stop recording.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import threading\n",
    "\n",
    "def record_audio(filename=\"conversation.wav\"):\n",
    "    chunk = 1024  \n",
    "    format = pyaudio.paInt16  \n",
    "    channels = 1  \n",
    "    rate = 16000  \n",
    "    frames = []\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=format, channels=channels, rate=rate, input=True, frames_per_buffer=chunk)\n",
    "    \n",
    "    print(\"Recording... Press Enter to stop recording.\")\n",
    "    \n",
    "    def record():\n",
    "        while not stop_event.is_set():\n",
    "            data = stream.read(chunk)\n",
    "            frames.append(data)\n",
    "\n",
    "    stop_event = threading.Event()\n",
    "    recorder_thread = threading.Thread(target=record)\n",
    "    recorder_thread.start()\n",
    "    \n",
    "    # Wait for user input to stop recording\n",
    "    input()  # Press Enter to stop\n",
    "    stop_event.set()\n",
    "    recorder_thread.join()\n",
    "\n",
    "    print(\"Recording stopped.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Save the recording\n",
    "    wf = wave.open(filename, \"wb\")\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(format))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    print(f\"Audio saved as {filename}\")\n",
    "\n",
    "# Run the function\n",
    "record_audio()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the text from the audio file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"conversation.wav\",fp16=False)\n",
    "print(\"Transcript:\", result['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the summary of the conversation from gpt-4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Set up your API key (replace 'api-key' with your actual key)\n",
    "client = OpenAI(api_key=api_key)\n",
    "def summarize_conversation(transcript):\n",
    "    prompt = f\"\"\"\n",
    "    This is a doctor-patient conversation. Your task is to analyze the transcript and provide a summary of the interaction along with the following information:\n",
    "\n",
    "    1. Symptoms: List all symptoms mentioned by the patient.\n",
    "    2. Diagnosis: Mention the diagnosis made by the doctor, if available.\n",
    "    3. Tests/Procedures: Identify any tests, procedures, or investigations advised by the doctor, if any.\n",
    "    4. Medications: List any medications prescribed, if any.\n",
    "    5. Follow-up: Mention if a follow-up or next appointment was suggested, if any.\n",
    "\n",
    "    Here is the transcript of the conversation:\n",
    "\n",
    "    {transcript}\n",
    "\n",
    "    Please provide a detailed summary along with the extracted information.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call the GPT model\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant for summarizing text. Provide complete, coherent summaries.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=1000,  # Increased from 50 to 150\n",
    "            temperature=0.2,\n",
    "            presence_penalty=0.0,\n",
    "            frequency_penalty=0.0,\n",
    "\n",
    "        )\n",
    "    summary = response.choices[0].message.content.strip()\n",
    "    return summary\n",
    "\n",
    "# Sample doctor-patient conversation\n",
    "conversation = result['text']\n",
    "\n",
    "# Get the summary and key points\n",
    "summary = summarize_conversation(conversation)\n",
    "print(\"Summary and Extracted Information:\\n\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
